# 文法解析器——语法解析器的自动生成工具



## 现实中已经存在的例子

### Yacc+Lex

Lex和 Yacc是一对配对工具。Lex将文件分解为成组的“记号（tokens）”，大体上类似于单词。Yacc接受成组的记号，并将它们装配为高层次的结构，类似于句子。Yacc设计用来处理Lex的输出；同样，Lex的输出很大程度上设计用于为某类解析器提供数据。

这两位的实现有很多，比如GNU旗下的bison和flex，以及伯克利的byacc，和IBM的plex等。

#### Lex：一个词汇分析器生成器

词汇分析器是一个将输入拆分为经过识别的片断的程序。 例如，一个简单的词汇分析器可能会为输入的单词进行计数。Lex可以接受规范文件并构建一个相应的词汇分析器，下面是摘自 flex的手册的一个简单的 Lex程序：

##### 1. 使用 Lex为单词计数

```yacas
int num_lines = 0, num_chars = 0;
%%
\n      ++num_lines; ++num_chars;
.       ++num_chars;
%%

	main() 
	{
		yylex();
		printf("# of lines = %d, # of chars = %d\n", num_lines, num_chars);
	}
```

这个程序有三个部分，用 `%%` 符号隔开。第一部分和最后一个部分是普通又古老的 C 代码。中间是由一系列的规则构成，Lex按照这些规则生成一段词汇分析器的代码。每一个规则依次包含一个正则表达式以及该正则表达式得到匹配时要运行的一些代码。任何没有得到匹配的文本则简单地拷贝到标准输出。

上面这段代码其实是一个完整的程序，如果用Lex来编译运行的话，生成的二进制文件会去做你定义好的事情。在这种情况下，很容易看到发生了什么。换行永远都会匹配第一个规则。任何其他字符都会匹配第二个规则。

Lex依次尝试每一个规则，尽可能地匹配最长的输入流。如果有一些内容根本不匹配任何规则， 那么 Lex将只是把它拷贝到标准输出；这种行为通常是不受欢迎的。一个简单的解决方案是在最后添加一个可以匹配任何内容的规则，这个规则不做任何事情也不发出任何类型的诊断信息。

使得Lex实用原因在于，它可以处理更加复杂的规则。例如，识别C标识符的规则可能是这样：

```yacas
[a-zA-Z_][0-9a-zA-Z_]* { return IDENTIFIER; }
```

所使用的语法是普通而古老的正则表达式语法。Lex其中一个扩展让你可以为通用的模式命名。 您可以在Lex程序的第一部分中第一个 `%%` 之前为其中 的一部分定义名称：

```yacas
DIGIT [0-9]ALPHA [a-zA-Z]ALNUM [0-9a-zA-Z]IDENT [0-9a-zA-Z_]
```

然后就可以在规则部分将其名称放置在大括号内来反向引用它们：

```yacas
({ALPHA}|_){IDENT}* { return IDENTIFIER; }
```

#### Yacc：另一个编译器的编译器

经过Lex的处理，现在我们已经有了一连串的单词，但是如何对这些单词背后代表的结构进行识别，这就是Yacc需要做的事情。Yacc可以让文法的编写者描述希望如何处理由Lex分类好的符号。类似于这样的语法：

##### 2. 一个简单的 yacc 语法

```yacas
value:
	  VARIABLE
	| NUMBER
expression:
	  value '+' value
	| value '-' value
```

一个变量、一个加号或者一个数字都可以是一个表达式。管道字符（ `|` ）表明可供选择。Lex生成的 符号称为 *终结符（terminals）*或者 *记号（tokens）*。从它们组合而来的内容称为 *非终结符（non-terminals）*。所以，在这个例子中， `NUMBER`是一个 终结符；Lex生成了NUMBER。相反， `value` 是一个非终结符，它是通过组合终结符而创建出来的。

类似于 Lex文件，Yacc文件也是由使用 `%%` 标志隔开的部分构成。 与Lex文件一样，Yacc文件也由三部分构成（其中最后一个部分是可选的），其内容将会被写入到C文件中执行。

#### 处理Yacc的解析

通常来说，可以定义一个映射到Yacc将要处理的对象的数据类型。这个数据类型是一个 C `union`对象，在 Yacc文件的第一部分使用 `%union` 声明来定义。定义了记号以后，可以为 它们指定一个类型。例如以下几种示例：

##### 3. 一个最简化的 %union 声明+使用 yylval

```yacas
%union {
    long    value;
}
%token <value>    NUMBER
%type <value> expression

[0-9]+  {
        yylval.value = strtol(yytext, 0, 10);
        return NUMBER;
    }
```

这样，当一个union对象获取到NUMBER值的时候，认为全局变量 `yylval` 所属的 `value` 成员就被赋予了有意义的常量。

yacc 允许您通过符号名引用表达式的组成部分。当解析非终结符时，进入解析器的组成部分被 命名为 `$1` 、 `$2` ，依次类推；它将向 高层解析器返回的值名为 `$$` 。例如：

##### 4. 在 yacc 中使用变量

```yacas
expression: NUMBER '+' NUMBER { $$ = $1 + $3; }
```

注意，字面量加号是 `$2` ，没有有意义的值，但它仍然要占一个位置。 不需要指定一个“return”或者任何其他内容：只是分配一个奇妙的名称 `$$` 。 `%type` 声明表明了 `expression` 非终结符还 使用了 union 的 `value` 成员。

※本节内容来自IBM Developer社区，内容有改动。

[^如果想要了解关于Lex和Yacc的更多详细用法，请参阅]: https://www.ibm.com/developerworks/cn/linux/sdk/lex/index.html



### Antlr v4

Antlr是一个用Java实现的类LL文法分析工具。

## 从头实现一个LL(1)文法解析器

### 功能边界确定

需要包含以下几个组件和附件：

1. 一个需要指定关键字的词法分析器
2. 一个语法分析器，包含LL(1)分析表
3. 一个AST基类
4. 一个文法规则录入工具
5. 一个代码生成器，用于生成AST子类

### 实现方式

#### 词法分析器——Lex

词法分析器应该为每一个可能读取到的字符设置一个状态码，状态码是用来引导有限自动机进行状态转移的。每个状态码事实上对应了完整的有限自动机的一个子自动机，在这里表现为一个函数的形式。

这样，在每个子自动机/函数内部，就可以根据状态码再次进行独立的处理，方便进行分词。

需要注意的是，划分字符所属的状态时，如果两个字符的作用有任何不一致，那么一定要分到两个状态码下面去。因为如果分开的话只需要在每个子自动机里多添加一个节点两条路径；不分开的话就要在不同的节点里写逻辑判断，这样难度更大而且更容易出错。

#### 语法分析器——Parser
Parser由一个主控程序和一个分析表组成，根据Lex传递的符号流和分析表内容改写分析栈。

为了方便构造Parser，可以采用表驱动的方式来编写parser类，尽管状态机更方便编译器及CPU进行代码优化与条件预测，但是这样就不能方便的根据情况随时调整状态机内部的代码。

工作流程为：
①. 取符号 
②. 查表 
③. 根据分析表项改写分析栈

直到分析栈中没有符号且符号流中也没有符号为止。

分析内容请参阅2.1节。

#### 文法规则录入工具——Reader

因为现在这个工具对于词法分析器的掌控力还是弱了点，所以暂时没有放在第一位介绍。以后迟早会放在第一位的（确信）。

录入工具的主要作用就是读取文法文件。在这里，为了简化分析步骤，没有采用“文法文件内部引用文法文件”的方案，而是用了“外部配置文件依次加载文法文件”的方案；并且指定了三个必须加载的文法文件（虽然你可以不往里面写东西），依次为keyword.grammer / mark.grammer / annotation.grammer，分别代表关键字/符号/注释三类文法符号。Reader会首先加载这三个文件并将其填到Lex中；然后按行分析grammer.list文件，从上至下加载其中的文件。所以要求后加载的文件的所有产生式右部使用的文法符号都必须已经包含在先加载和正在加载的文件中，否则会报错表示“文法未定义”。

此后，Reader会计算所有非终结符的follow集（当然会先计算出所有first集）

#### AST自动生成（JavaPoet包 与 Tree_Span包）
每个文法节点均包含三个通用protected方法：①添加子节点 ②设置属性 ③获取所有子节点

另外还有一个通用属性“节点名称”以及对应的get/set方法。

三个protected方法是用于继承并且重写的，根据每个节点的不同会有所变化。三个protected方法重写的规则是这样的：
##### 1. 添加子节点
一般来说，如果一条文法产生式中存在表述复杂的非终结符，那么就需要添加子节点，表示这个地方还有很复杂的展开，需要继续向下寻找详细的处理过程。
如果这样的节点有很多的话，可以加一个Collection类来方便遍历；推荐用List，因为很多语言的代码顺序和处理顺序是相关的。
##### 2. 添加属性
有两种情况，如果一个非终结符是由多条简单的只包含终结符的产生式组成的，那么很大概率这个非终结符代表的是某种属性。另外一种可能就是多条产生式的形式
类似，但是中间有一个关键终结符不一样，那么很可能那里就是一个属性。
##### 3.获取所有子节点
将第一条所述的所有Collection类集中到一个Collection中输出。应该说这种方法不会很常用。