# Lex与Parser的构造

## LEX的构造
### 词法分析器的功能
   词法分析的目的是读取字符流，输出单词符号流。大部分的程序语言中，单词符号分为以下五种：  
1.	关键字：由程序语言定义的固定含义的标识符。这些单词通常不用于表示一般自定义的标识符。  
2.	标识符：用来表示各种用户自定义的名称，例如变量名称、函数名称、类型/对象名称等。  
3.	常量：例如数、字符串、布尔常量等。  
4.	运算符：比如+、-、×、÷。  
5.	定界符：比如逗号、句号、分号、括号、注释符号等。  

### 词法分析器的输出形式
   为了方便此后的程序识别，一般使用一个编号来标记单词的种类，加上一定的属性，构成二元输出式形如：  
			（单词种类号码，单词符号属性值）
   单词种类号码一般采用整数编码，在分类上，一般按照语义接近的分为一组来执行；如果遇到多含义的单词也可以专门新开一个种类。定界符一般是每个符号一个种类。单词符号的属性一般表示单词的特征，比如多个int变量标识符之间，需要依靠属性值区分标识符的名称和实际值。  

### 分词的机制
   一种语言当中存在关键字和非关键字的区别，那么如何从一连串的字符中挑出它们？这就涉及到了分词的机制。分词的艺术在于如何正确巧妙的利用定界符、运算符、空白符甚至语法树来框定非关键字的范围。  
   首先我们需要一个记录所有关键字的列表。  
   如果希望严格的限定用户完全不能使用关键字做任何其他事情的话，那么可以在每识别一个符号的时候就去列表中查询，但是显然，一般的语言都不会采取这样严格的策略。  
   退而求其次的方案是，将一个单词（不论什么样的单词）作为一个整体进行查表的操作；这样只要关键字单独的出现，没有和其他组成标识符的符号混合在一起的话，就一定可以查出来。  
   如果要求关键字也可以作为标识符使用的话（比如Fortran），就需要基于缓冲的超前搜索、甚至语法树来辅助分析。  

#### 常数的识别
   常数识别的问题在于，要识别正负号和一个多义字符 '.'，如果要加上科学计数法或者数学常数的话那么情形会更加复杂。因此需要专门的常数处理函数，用来匹配状态转移图中关于常数的子图。  
#### 运算符与定界符的识别

   各种语言中，除了简单的单个符号组成的运算符或者定界符之外，还有很多由多个有意义的符号组成的多符号运算符/定界符，这些单词的识别只能使用超前搜索来解决。  
   极端一点的，例如Java/C当中的可变长参数中，出现“...”连用的用法，进一步扩充了英文句号的语义。

#### 超前搜索设计与分词方案

先看Fortran语言中的两个合法句子：  
① DO99K=1,10 （循环语句，变量名是99K）  
② DO99K=1.10 （赋值语句，变量名是DO99K）  

​	为了正确识别上两者的区别，我们读取了“DO”之后，不能马上判断这是一个关键字，需要先跳过中间所有符号去搜索下一个等号在哪里。如果有等号，接着扫描到下一个定界符，分辨出是逗号还是句号之后，才能反过来判定前面的“DO99K”到底是个什么东西。  

再看Java语言中的两个合法句子：  
int i;
①if(i=9)
②if(i==-9)

​	为了正确识别上两者的符号到底是布尔运算符还是赋值符号，同样需要一直搜索到下一个数字/字母才能确认之前的符号串里到底包含了多少运算符号。②在划分单词的时候使用贪心方式来分割，得到一个布尔运算符和一个负号。

[^杂谈]: 不无恶意的揣度一下Fortran的设计方式，我严重怀疑他们是因为长度短的变量名称不够用才出此下策。用编译时的内存消耗来减少存储源代码的空间需求。这种语法设计对于观看的人来说无疑是非常不友好的。

##### 工程化分词艺术（原创）

​	如果你写的代码足够多，你就会由一定的感受：单个符号是分成多个种类的，单词和单词之间也是有一些自然的边界的。这些边界使得基于状态的超前搜索（我自己的命名）成为可能。  
​	例如，将字符分为以下几种：  
1. 无条件停顿字符：当遇到这样的符号时，无论如何都停下来，将缓冲区内的字符串进行查表操作，如果未找到对应单词的话按照已知状态进行处理。一般包含空格、换行、回车、分号。  
2. 字母字符：遇到这样的符号时，如果已知状态不是字母的话就停下来，将缓冲区内的字符串进行查表操作，否则将当前字符置入缓冲区。  
3. 符号字符：遇到这样的符号时，需要按照更加精细的判断决定当前字符是否应该加入到缓冲区中。因为符号当中会有一些特殊的字符，甚至在某些语言中的大部分符号都是有各种特殊意义的。此时就需要根据完整的词法定义，分割完整的状态转移图，生成针对不同类型单词的局部状态转移图，然后根据这些子图写单独的处理函数。例如针对浮点型数值，+/-/.就不能简单的认定成符号。  
4. 还有一个作为特例的单/双引号，这个需要单独识别。  

此后，针对符号字符的识别复杂度，设计如下的方案：  
1. 设计一个三状态枚举开关类，分别用stop、mark、letter标记三个状态。  
2. 逐字符读取语句，判断其所属的类型。（stop/mark/letter）  
3. 与上一个字符的类型进行equal比较，判断当前是否需要停止读取，生成单词。
4. 如果当前状态表明停止读取的话，首先将缓冲区字符串进行查表操作，查到的话按照关键字处理；查不到的话按照变量或者常量处理
5. 如果当前是符号，上一个字符也是符号，那么检查缓冲区字符串和当前字符组成的字符串是否在关键字表里，如果不在，则将缓冲区已有内容按照关键字处理。
6. 读取到单/双引号时，转入字符串处理程序。

### 单词属性的识别

​	一般来讲，单词属性只需要关注非关键字，例如常量、类型名称、变量等符号的识别。但是多义符号是需要着重研究的地方。

​	大部分单词属性可以根据其前缀单词直接推断出来，少部分的需要参考其本身结构。

[^杂谈]: 我写了一个简化版的自动分词器放在项目code文件夹里。只需要初始化的时候放一个正常的关键字/符号列表进去就可以工作。



## Parser的构造
### 语法分析器的功能
​	语法分析器的任务是在词法分析识别出的单词符号流的基础上，分析并判定这个语句是否符合预定义的语法规则。并且将语句进行格式化，方便进行语义分析。最常见的格式化方法是转换成抽象语法树（AST）。

### 语法分析器的类型
1. 自动机类型：最为直观可工程化实现的方式，但是想要正确的、无歧义的分析语言还需要做很多重复工作。
2. 动作外置的语法树类型：外部总控程序为主，通过识别结点类型执行规定工作。
3. 动作内置的语法树类型：外部总控程序为辅，每个结点仅包含自身相关的动作。

### 语法分析器的构造

首先总结一个Parser为了成功执行分析工作需要哪些固定的数据结构。

1. 关键字/算符表
2. 语法结构

语法分析器的难度其实甚至不如词法分析器（仅代表个人感受），核心要点第一在于语法的定义是否合规；第二在于语法结构的数据结构定义，语法定义其实已经包含在语法数据结构当中了。只要明晰这两点，总控程序的编写并不困难。

[^杂谈]:我当初写语法分析器的时候，直接采用了状态转移+封闭特定状态的办法。所以整个分析器写的异常精简。如果不算一个很占地方的switch case语句的话，核心代码只有不到40行。
[^]: 新的手动递归下降语法分析器正在编写中，由于涉及的类、文件、概念过多，我会发布在个人的GitHub里，里面还有更加精确的多状态词法分析器，可以解析更多的单词，并且带有忽略注释功能。

